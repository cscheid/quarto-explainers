<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head>
  <meta charset="utf-8">
  <meta name="generator" content="quarto-(Local Development)">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Linear Regression</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script src="../site_libs/quarto-nav/quarto-nav.js"></script>
  <script src="../site_libs/quarto-html/quarto.js"></script>
  <script src="../site_libs/quarto-html/popper.min.js"></script>
  <script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
  <script src="../site_libs/quarto-html/clipboard.min.js"></script>
  <script src="../site_libs/quarto-html/anchor.min.js"></script>
  <script src="../site_libs/quarto-html/quarto-html.js"></script>
  <link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
  <link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
  <script src="../site_libs/bootstrap/bootstrap.min.js"></script>
  <link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
  <link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" href="styles.css">
</head>
<body>
<div id="quarto-search-results"></div>
 <!-- /navbar/sidebar -->
<div class="container-fluid quarto-container d-flex flex-column page-layout-article" id="quarto-content">
<div class="row flex-fill">
  <div id="quarto-toc-sidebar" class="col col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-toc order-last"><nav id="TOC" role="doc-toc">
<h2 id="toc-title">On this page</h2>
<ul>
<li><a href="#modeling-data-for-linear-regression" class="nav-link active" data-scroll-target="#modeling-data-for-linear-regression">Modeling data for linear regression</a></li>
<li><a href="#solving-a-linear-regression-model" class="nav-link" data-scroll-target="#solving-a-linear-regression-model">Solving a linear regression model</a>
<ul class="collapse">
<li><a href="#setting-up-the-matrices" class="nav-link" data-scroll-target="#setting-up-the-matrices">Setting up the matrices</a></li>
<li><a href="#solving-the-system-of-equations" class="nav-link" data-scroll-target="#solving-the-system-of-equations">Solving the system of equations</a></li>
</ul></li>
<li><a href="#demo" class="nav-link" data-scroll-target="#demo">Demo</a></li>
</ul>
</nav></div>
  <div class="col mx-auto col-sm-12 col-md-9 col-lg-7 px-lg-4 pe-xxl-4 ps-xxl-0">
<main>
<header id="title-block-header">
<div class="quarto-title-block"><div><h1 class="title">Linear Regression</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</header>

<script src="https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.4/lodash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/numeric/1.2.6/numeric.min.js"></script>
<p>Linear regression is one of simplest ways of building a model that can make predictions from existing data (the “training data”). Regression models are used to predict numbers (“what will the temperature be tomorrow?”), while classification models are used to predict discrete outcomes (“will it rain tomorrow?”).</p>
<p>Although linear regression is an elementary method in data analysis that has existed for 200 years, it is robust, flexible, easy to compute, easy to understand, often performs quite well, and, just as importantly, the foundation upon which many modern regression models are built.</p>
<p>We give a more general perspective <a href="linear_least_squares.html">in a separate piece</a>.</p>
<section id="modeling-data-for-linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="modeling-data-for-linear-regression">Modeling data for linear regression</h2>
<p>There are many ways to build a model from data. In regression, the training data is given as a set of pairs of <em>independent</em> and <em>dependent</em> variables. Independent variables are the part of the data our finished model will use to make predictions; dependent variables are what the predictions should be. So our training data always has both values of the dependent and independent variables, but our testing data only has the values of the independent variables. The job of the model is exactly to predict the value of the dependent variable.</p>
<p>Let’s get a little more concrete. Imagine you are designing a computerized hygrometer: an instrument to read moisture content from the air. You are in charge of writing the software that will read varying amounts of voltage from the sensor and convert those readings into humidity measurements. As input, you are given a set of voltage readings and associated humidity values (the humidity values having been collected by some other trusted method). Let us call <span class="math inline">\(x\_i\)</span> the voltage values, and <span class="math inline">\(y\_i\)</span> the humidity values.</p>
<p>Our first decision is as to what model we will use for the predictions. This decision cannot come alone from the data (although <a href="model_assessment.html">we will later discuss methods to help with this</a>). In linear regression, the fundamental assumption is that the model is, well, <em>linear</em>: we look for the linear combination<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> of simpler, known models that best predicts the training examples.</p>
<p>For example, a model that says the humidity <span class="math inline">\(y\)</span> will be predicted as</p>
<p><span class="math display">\[ y = a x + b \]</span></p>
<p>is a linear regression model, because we are trying to predict an unknown value (<span class="math inline">\(y\)</span>) from a linear combination of known values (<span class="math inline">\(x\)</span> and <span class="math inline">\(1\)</span>). To <em>solve</em> a linear regression model is to find the values of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> that best match the training data, in hopes that it will best predict the test data.</p>
</section>
<section id="solving-a-linear-regression-model" class="level2">
<h2 class="anchored" data-anchor-id="solving-a-linear-regression-model">Solving a linear regression model</h2>
<p>In order to find the <em>best</em> values for <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, we first need to define what we mean by <em>best</em>. Here, we will use a very simple notion, which says that we want to minimize how bad our model does over the entirety of the training data, and that we will count how badly the model does at each training point by the square of the difference between the predicted value and the observed value:</p>
<p><span class="math display">\[ E = \sum_i (y_i - (ax_i + b))^2 \]</span></p>
<p><span class="math inline">\(E\)</span> stands for the “energy” of the model, or the “error” of the model, and we want to find the model that minimizes the error.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> This is simply a matter of taking the derivative of <span class="math inline">\(E\)</span> with respect to <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, setting those values to zero, and solving the resulting system of equations.</p>
<p>The crucial observation in linear models is that, since we know the values <span class="math inline">\(y\_i\)</span> and <span class="math inline">\(x\_i\)</span> at training time, when we take derivatives of <span class="math inline">\(E\)</span>, the resulting expressions are always linear functions of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. This is true even if the model we are fitting uses non-linear functions. For example, imagine that our model was, instead,</p>
<p><span class="math display">\[ y = a x^2 + b x + c. \]</span></p>
<p>Even though the model would be fitting parabolic curves to the data (instead of linear fits), the process of combining the simpler models (<span class="math inline">\(1\)</span>, <span class="math inline">\(x\)</span> and <span class="math inline">\(x^2\)</span>) is still linear <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<section id="setting-up-the-matrices" class="level3">
<h3 class="anchored" data-anchor-id="setting-up-the-matrices">Setting up the matrices</h3>
</section>
<section id="solving-the-system-of-equations" class="level3">
<h3 class="anchored" data-anchor-id="solving-the-system-of-equations">Solving the system of equations</h3>
<p>TBF.</p>
</section>
</section>
<section id="demo" class="level2">
<h2 class="anchored" data-anchor-id="demo">Demo</h2>
<p>TBF. Click on the plot to add points.</p>
<div id="linear-regression-linear-demo">

</div>
<!-- -->
<div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title anchored" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Linear Regression</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">"https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.4/lodash.min.js"</span><span class="kw">&gt;&lt;/script&gt;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;script</span> <span class="er">src</span><span class="ot">=</span><span class="st">"https://cdnjs.cloudflare.com/ajax/libs/numeric/1.2.6/numeric.min.js"</span><span class="kw">&gt;&lt;/script&gt;</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>Linear regression is one of simplest ways of building a model that can</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>make predictions from existing data (the "training data"). Regression</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>models are used to predict numbers ("what will the temperature be</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>tomorrow?"), while classification models are used to predict discrete</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>outcomes ("will it rain tomorrow?").</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>Although linear regression is an elementary method in data analysis</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>that has existed for 200 years, it is robust, flexible, easy to</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>compute, easy to understand, often performs quite well, and, just as</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>importantly, the foundation upon which many modern regression models</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>are built.</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>We give a more general perspective <span class="co">[</span><span class="ot">in a separate piece</span><span class="co">](linear_least_squares.html)</span>.</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modeling data for linear regression</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>There are many ways to build a model from data. In regression, the</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>training data is given as a set of pairs of *independent* and</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>*dependent* variables. Independent variables are the part of the data</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>our finished model will use to make predictions; dependent variables</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>are what the predictions should be. So our training data always has</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>both values of the dependent and independent variables, but our</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>testing data only has the values of the independent variables. The job</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>of the model is exactly to predict the value of the dependent</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>variable.</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>Let's get a little more concrete. Imagine you are designing a</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>computerized hygrometer: an instrument to read moisture content from</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>the air. You are in charge of writing the software that will read</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>varying amounts of voltage from the sensor and convert those readings</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>into humidity measurements. As input, you are given a set of voltage</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>readings and associated humidity values (the humidity values having</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>been collected by some other trusted method). Let us call $x<span class="sc">\_</span>i$ the</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>voltage values, and $y<span class="sc">\_</span>i$ the humidity values.</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>Our first decision is as to what model we will use for the</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>predictions. This decision cannot come alone from the data (although</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">we will later discuss methods to help with this</span><span class="co">](model_assessment.html)</span>). In</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>linear regression, the fundamental assumption is that the model is, well,</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>*linear*: we look for the linear combination<span class="ot">[^1]</span> of simpler, known models</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>that best predicts the training examples.</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>For example, a model that says the humidity $y$ will be predicted as</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>$$ y = a x + b $$</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>is a linear regression model, because we are trying to predict an</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>unknown value ($y$) from a linear combination of known values ($x$ and</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>$1$). To *solve* a linear regression model is to find the values of</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>$a$ and $b$ that best match the training data, in hopes that it will best</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>predict the test data.</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="fu">## Solving a linear regression model</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>In order to find the *best* values for $a$ and $b$, we first need to</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>define what we mean by *best*. Here, we will use a very simple notion,</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>which says that we want to minimize how bad our model does over the</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>entirety of the training data, and that we will count how badly the</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>model does at each training point by the square of the difference</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>between the predicted value and the observed value:</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>$$ E = \sum_i (y_i - (ax_i + b))^2 $$</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>$E$ stands for the "energy" of the model, or the "error" of the model,</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>and we want to find the model that minimizes the error.<span class="ot">[^2]</span> This is simply</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>a matter of taking the derivative of $E$ with respect to $a$ and $b$,</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>setting those values to zero, and solving the resulting system of</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>equations.</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>The crucial observation in linear models is that, since we know the</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>values $y<span class="sc">\_</span>i$ and $x<span class="sc">\_</span>i$ at training time, when we take derivatives of</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>$E$, the resulting expressions are always linear functions of $a$ and</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>$b$. This is true even if the model we are fitting uses non-linear functions. </span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>For example, imagine that our model was, instead,</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>$$ y = a x^2 + b x + c. $$</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>Even though the model would be fitting parabolic curves to the data</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>(instead of linear fits), the process of combining the simpler models</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>($1$, $x$ and $x^2$) is still linear <span class="ot">[^3]</span>.</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a><span class="fu">### Setting up the matrices</span></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a><span class="fu">### Solving the system of equations</span></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>TBF.</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a><span class="fu">## Demo</span></span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>TBF. Click on the plot to add points.</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">id</span><span class="ot">=</span><span class="st">"linear-regression-linear-demo"</span><span class="kw">&gt;&lt;/div&gt;</span></span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a><span class="ot">[^1]: </span>A linear combination of a set of vectors is a weighted sum of those vectors, where the weights can be arbitrary values.</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a><span class="ot">[^2]: </span>Different generalizations of this error function make up a surprisingly large fraction of modern methods in data analysis.</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a><span class="ot">[^3]: </span>See <span class="co">[</span><span class="ot">linear least squares</span><span class="co">]()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
<!-- -->
</section>
<section class="footnotes" role="doc-endnotes"><h2>Footnotes</h2>

<ol>
<li id="fn1" role="doc-endnote"><p>A linear combination of a set of vectors is a weighted sum of those vectors, where the weights can be arbitrary values.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Different generalizations of this error function make up a surprisingly large fraction of modern methods in data analysis.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>See <a href="">linear least squares</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</main>
<div class="page-navigation ">
  <div class="nav-page nav-page-previous">
  </div>
  <div class="nav-page nav-page-next">
  </div>
</div>
</div> <!-- /main column -->
</div> <!-- /row -->
</div> <!-- /container fluid -->


</body></html>